{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column Descriptions\n",
    "\n",
    "\n",
    "> - ACTION:\tACTION is 1 if the resource was approved, 0 if the resource was not\n",
    "- RESOURCE:\tAn ID for each resource\n",
    "- MGR_ID :\tThe EMPLOYEE ID of the manager of the current EMPLOYEE ID record; an employee may have only one manager at a time\n",
    "- ROLE_ROLLUP_1\t:Company role grouping category id 1 (e.g. US Engineering)\n",
    "- ROLE_ROLLUP_2\t:Company role grouping category id 2 (e.g. US Retail)\n",
    "- ROLE_DEPTNAME\t:Company role department description (e.g. Retail)\n",
    "- ROLE_TITLE:\tCompany role business title description (e.g. Senior Engineering Retail Manager)\n",
    "- ROLE_FAMILY_DESC:\tCompany role family extended description (e.g. Retail Manager, Software Engineering)\n",
    "- ROLE_FAMILY:\tCompany role family description (e.g. Retail Manager)\n",
    "- ROLE_CODE : \tCompany role code; this code is unique to each role (e.g. Manager)\n",
    "\n",
    "\n",
    "##  ref :\n",
    "\n",
    "- http://www.chioka.in/kaggle-competition-solutions/\n",
    "- https://github.com/codelibra/Amazon-Employee-Access-Challenge/blob/master/Amazon-Employee-Access-Challenge.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In V3, we do 2 approaches :\n",
    "\n",
    "    - 1. Normalization, regularization  <---- seems would make predict accuracy WORSE\n",
    "    - 2. Resampling : Oversampling, Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/envs/g_dash/lib/python3.4/site-packages/IPython/core/magics/pylab.py:161: UserWarning: pylab import has clobbered these variables: ['clf']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "# Load basics library \n",
    "\n",
    "import pandas as pd, numpy as np\n",
    "%matplotlib inline\n",
    "%pylab inline\n",
    "import seaborn  as sns \n",
    "import pylab as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load CSVs\n",
    "\n",
    "df_train = pd.read_csv('~/Kaggle.com_mini_project/Amazon_access/train.csv')\n",
    "df_test = pd.read_csv('~/Kaggle.com_mini_project/Amazon_access/test.csv')\n",
    "sampleSubmission = pd.read_csv('~/Kaggle.com_mini_project/Amazon_access/sampleSubmission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help function \n",
    "\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, explained_variance_score, mean_absolute_error\n",
    "from imblearn.under_sampling import RandomUnderSampler \n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def sample_split(data):\n",
    "    #data =  data[selected_feature]\n",
    "    relevent_cols = list(data)\n",
    "    data_=data.values.astype(float)             \n",
    "    Y = data_[:,0]\n",
    "    X = data_[:,1:]\n",
    "    test_size = .3\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state = 3)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "def reg_analysis(model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    prediction = model.predict(X_test)\n",
    "    #Calculate Variance score\n",
    "    Variance_score = explained_variance_score(y_test, prediction)\n",
    "    print ('Variance score : %.2f' %Variance_score)\n",
    "    #Mean Absolute Error\n",
    "    MAE = mean_absolute_error(y_test, prediction)\n",
    "    print ('Mean Absolute Error : %.2f' %MAE)\n",
    "    #Root Mean Squared Error\n",
    "    RMSE = mean_squared_error(y_test, prediction)**0.5\n",
    "    print ('Mean Squared Error : %.2f' %RMSE)\n",
    "    #RÂ² score, the coefficient of determination\n",
    "    r2s = r2_score(y_test, prediction)\n",
    "    print ('R2  score : %.2f' %r2s)\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def normalize_(df):\n",
    "    result = df.copy()\n",
    "    feature_names = list(df.columns[1:])\n",
    "    for feature_name in feature_names:\n",
    "        max_value = df[feature_name].max()\n",
    "        min_value = df[feature_name].min()\n",
    "        result[feature_name] = (df[feature_name] - min_value) / (max_value - min_value)\n",
    "    return result\n",
    "\n",
    "\n",
    "def oversampling(df):\n",
    "    y = df['ACTION']\n",
    "    X = df[df.columns.difference(['ACTION'])].as_matrix()\n",
    "    # Apply random over-sampling\n",
    "    ros = RandomOverSampler()\n",
    "    X_oversampled, y_oversampled = ros.fit_sample(X, y)\n",
    "    return X_oversampled, y_oversampled\n",
    "\n",
    "\n",
    "\n",
    "def undersampling(df):\n",
    "    y = df['ACTION']\n",
    "    X = df[df.columns.difference(['ACTION'])].as_matrix()\n",
    "    # Apply random under-sampling\n",
    "    ros = RandomUnderSampler()\n",
    "    X_undersampled, y_undersampled = ros.fit_sample(X, y)\n",
    "    return X_undersampled, y_undersampled\n",
    "\n",
    "\n",
    "def test_data_predict(df):\n",
    "    X_train_, X_test_, y_train_, y_test_ = sample_split(df)\n",
    "    df_predict=pd.DataFrame()\n",
    "    # submit prediction from TEST data \n",
    "    df_predict['Action'] = clf_svr.predict(df_test.iloc[:,1:])\n",
    "    df_predict.index.name = 'ID'\n",
    "    # make index feat submission form \n",
    "    # https://www.kaggle.com/c/amazon-employee-access-challenge/submit\n",
    "    df_predict.index = df_predict.index + 1\n",
    "    print (df_predict.head())\n",
    "    return df_predict\n",
    "\n",
    "def save_model(model):\n",
    "    try:\n",
    "        with open('/Users/yennanliu/Kaggle.com_mini_project/Amazon_access/final_tuned_model.pkl', 'wb') as fid:\n",
    "            pickle.dump(model, fid)\n",
    "            print ('model save success')\n",
    "    except:\n",
    "        print ('saving fail')\n",
    "    \n",
    "def load_model():\n",
    "    with open('/Users/yennanliu/Kaggle.com_mini_project/Amazon_access/final_tuned_model.pkl', 'rb') as fid:\n",
    "        loaded_model = pickle.load(fid)\n",
    "        return loaded_model\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Normalization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_norm = normalize_(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = sample_split(df_train_norm)\n",
    "\n",
    "X_train, X_test, y_train, y_test = sample_split(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1') Selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selescted_feature = ['ACTION','ROLE_ROLLUP_1', 'ROLE_ROLLUP_2', 'ROLE_FAMILY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train[selescted_feature]\n",
    "\n",
    "df_train_feautre = df_train[selescted_feature] \n",
    "df_train_norm = normalize_(df_train_feautre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Resampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    30872\n",
       "0    30872\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# oversample \n",
    "\n",
    "X_oversampled, y_oversampled = oversampling(df_train)\n",
    "#X_oversampled, y_oversampled = oversampling(df_train_norm)\n",
    "\n",
    "pd.DataFrame(y_oversampled)[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train / test split for oversample data \n",
    "\n",
    "X_train_overs, X_test_overs, y_train_overs, y_test_overs = \\\n",
    " train_test_split(X_oversampled, y_oversampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123488"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_oversampled) + len(y_oversampled )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123488"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_overs) + len(X_test_overs) + len(y_train_overs) + len(y_test_overs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1897\n",
       "0    1897\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# undersample \n",
    "\n",
    "X_undersampled, y_undersampled = undersampling(df_train)\n",
    "#X_undersampled, y_undersampled = undersampling(df_train_norm)\n",
    "\n",
    "pd.DataFrame(y_undersampled)[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_unders, X_test_unders, y_train_unders, y_test_unders = \\\n",
    "train_test_split(X_undersampled, y_undersampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############## ML ##############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM classifier score =  0.999805649132\n",
      "[[7780    3]\n",
      " [   0 7653]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn import svm\n",
    "\n",
    "# for oversample dataset \n",
    "\n",
    "clf_svr = svm.SVC()\n",
    "clf_svr.fit(X_train_overs,y_train_overs)\n",
    "y_test_predict = clf_svr.predict(X_test_overs)\n",
    "\n",
    "print ('SVM classifier score = ', clf_svr.score(X_test_overs,y_test_overs))\n",
    "print (confusion_matrix(y_test_predict,y_test_overs ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores = cross_val_score(clf_svr, X_oversampled, y_oversampled, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.99967611,  0.99967611,  0.99951409,  0.99967606,  0.99959508])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_svr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model save success\n"
     ]
    }
   ],
   "source": [
    "### save model (pickle)\n",
    "\n",
    "save_model(clf_svr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### load model \n",
    "\n",
    "loaded_model = load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM classifier score =  0.481559536354\n",
      "[[439 492]\n",
      " [  0  18]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# for unsersample dataset \n",
    "\n",
    "clf_svr = svm.SVC()\n",
    "clf_svr.fit(X_train_unders,y_train_unders)\n",
    "y_test_predict = clf_svr.predict(X_test_unders)\n",
    "\n",
    "print ('SVM classifier score = ', clf_svr.score(X_test_unders,y_test_unders))\n",
    "print (confusion_matrix(y_test_predict,y_test_unders ))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM grid search \n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
    "#svr = svm.SVC()\n",
    "#clf = GridSearchCV(svr, parameters)\n",
    "#clf.fit(X_train_unders,y_train_unders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf_forest score : =  0.98127753304\n",
      "[[7780  289]\n",
      " [   0 7367]]\n"
     ]
    }
   ],
   "source": [
    "# Random forest \n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf_forest = RandomForestClassifier(random_state=0)\n",
    "clf_forest.fit( X_train_overs, y_train_overs)\n",
    "y_test_predict = clf_forest.predict(X_test_overs)\n",
    "print ('clf_forest score : = ', clf_forest.score(X_test_overs,y_test_overs))\n",
    "\n",
    "print (confusion_matrix(y_test_predict,y_test_overs ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bdt score =  0.873736719357\n",
      "[[6970 1139]\n",
      " [ 810 6517]]\n"
     ]
    }
   ],
   "source": [
    "# AdaBoostClassifier\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# Create and fit an AdaBoosted decision tree\n",
    "bdt = AdaBoostClassifier(RandomForestClassifier(n_estimators=1000, bootstrap=True, oob_score=True, n_jobs=-1, class_weight='balanced_subsample',max_depth=10),\n",
    "                         algorithm=\"SAMME\",\n",
    "                         n_estimators=1)\n",
    "\n",
    "bdt.fit(X_train_overs, y_train_overs)\n",
    "y_test_predict = bdt.predict(X_test_overs)\n",
    "print ('bdt score = ',bdt.score(X_test_overs,y_test_overs))\n",
    "print (confusion_matrix(y_test_predict,y_test_overs ))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
